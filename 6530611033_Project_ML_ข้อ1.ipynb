{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***6530611033 Project ML ข้อที่ 1***\n"
      ],
      "metadata": {
        "id": "gKInL9_7b7Yp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVWh3HjqP1iS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f5278a-b054-42f2-9794-ed9536ea0a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Access to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# library"
      ],
      "metadata": {
        "id": "6eg9Rld9BZcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ProcessPoolExecutor"
      ],
      "metadata": {
        "id": "xC0oMJDiRQ_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-NmoLw4TrbUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "โหลดข้อมูล"
      ],
      "metadata": {
        "id": "Y6ZJmwH0BgQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glass1_path = '/content/drive/MyDrive/Colab Notebooks/project_baselearning/แก้ว 1'\n",
        "glass2_path = '/content/drive/MyDrive/Colab Notebooks/project_baselearning/แก้ว 2'"
      ],
      "metadata": {
        "id": "1RMrmnUoRcU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เปลี่ยนไฟล์ wav to mp3"
      ],
      "metadata": {
        "id": "t7LIYVRJBmDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def convert_wav_to_mp3(wav_path, mp3_path):\n",
        "  try:\n",
        "    sound = AudioSegment.from_wav(wav_path)\n",
        "    sound.export(mp3_path, format=\"mp3\")\n",
        "    os.remove(wav_path)  # Delete the WAV file\n",
        "    print(f\"Converted {wav_path} to {mp3_path} and deleted the WAV file.\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "directory = \"/content/drive/MyDrive/Colab Notebooks/project_baselearning/แก้ว 1/\"\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "  if filename.endswith(\".wav\"):\n",
        "    wav_file_path = os.path.join(directory, filename)\n",
        "    mp3_file_path = os.path.join(directory, filename[:-4] + \".mp3\")\n",
        "    convert_wav_to_mp3(wav_file_path, mp3_file_path)\n",
        "\n",
        "directory = \"/content/drive/MyDrive/Colab Notebooks/project_baselearning/แก้ว 2/\"\n",
        "for filename in os.listdir(directory):\n",
        "  if filename.endswith(\".wav\"):\n",
        "    wav_file_path = os.path.join(directory, filename)\n",
        "    mp3_file_path = os.path.join(directory, filename[:-4] + \".mp3\")\n",
        "    convert_wav_to_mp3(wav_file_path, mp3_file_path)"
      ],
      "metadata": {
        "id": "fsyEnUBJnHD6",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0e02eb-6be5-4f0b-d1ab-c368ab425f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **โหลดข้อมูลสำหรับทำ feature vector**"
      ],
      "metadata": {
        "id": "tyE_blnIBp_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MFCC สร้าง feature_vector"
      ],
      "metadata": {
        "id": "_0Q7gHTsBzHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ฟังก์ชันดึงคุณสมบัติจากไฟล์เสียง\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        # โหลดไฟล์เสียง\n",
        "        y, sr = librosa.load(file_path, duration=3.0)\n",
        "        # ดึงคุณสมบัติต่าง ๆ\n",
        "        mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13).T, axis=0)\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)\n",
        "        spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr).T, axis=0)\n",
        "        tonnetz = np.mean(librosa.feature.tonnetz(y=y, sr=sr).T, axis=0)\n",
        "        zero_crossings = np.mean(librosa.feature.zero_crossing_rate(y=y).T, axis=0)\n",
        "        rms = np.mean(librosa.feature.rms(y=y).T, axis=0)\n",
        "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr).T, axis=0)\n",
        "        mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
        "        return np.hstack([mfcc, chroma, spectral_contrast, tonnetz,\n",
        "                          zero_crossings, rms, spectral_rolloff, mel])\n",
        "    except:\n",
        "        return None"
      ],
      "metadata": {
        "id": "X_sMjn23_oWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "labels = []\n",
        "\n",
        "# ดึง features สำหรับแก้ว 1\n",
        "for filename in tqdm(os.listdir(glass1_path)):\n",
        "    if filename.endswith(\".mp3\"):\n",
        "        file_path = os.path.join(glass1_path, filename)\n",
        "        features.append(extract_features(file_path))\n",
        "        labels.append(0)\n",
        "\n",
        "# ดึง features สำหรับแก้ว 2\n",
        "for filename in tqdm(os.listdir(glass2_path)):\n",
        "    if filename.endswith(\".mp3\"):\n",
        "        file_path = os.path.join(glass2_path, filename)\n",
        "        features.append(extract_features(file_path))\n",
        "        labels.append(1)\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n"
      ],
      "metadata": {
        "id": "UzZUnkblLYlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff94b250-2872-4464-e340-80a90a5b897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 52/52 [00:17<00:00,  2.90it/s]\n",
            "100%|██████████| 51/51 [00:14<00:00,  3.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ตรวจสอบว่ามีข้อมูลหรือไม่\n",
        "if len(features) > 0:\n",
        "    # แปลงข้อมูลเป็นอาเรย์และมาตรฐานข้อมูล\n",
        "    X = np.array(features)\n",
        "    y = np.array(labels)\n",
        "\n",
        "    # แบ่งข้อมูลเป็น Training และ Testing set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # ทำการมาตรฐานข้อมูล\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # การใช้ SMOTE เพื่อทำ oversampling ข้อมูลที่ไม่สมดุล\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # ปรับปรุงพารามิเตอร์ของ Decision Tree และเพิ่มการตั้งค่าใน Random Forest เพื่อให้ได้ประสิทธิภาพที่ดีขึ้น\n",
        "    classifiers = {\n",
        "        \"Decision Tree\": DecisionTreeClassifier(max_depth=150, min_samples_split=2, min_samples_leaf=1, random_state=42),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=1500, max_depth=100, min_samples_split=3, random_state=42),\n",
        "        \"Naive Bayes\": GaussianNB(),\n",
        "        \"Neural Network\": MLPClassifier(hidden_layer_sizes=(200, 100), max_iter=2000, alpha=0.01, random_state=42),\n",
        "        \"Logistic Regression\": LogisticRegression(C=0.1, max_iter=500, solver='liblinear', random_state=42)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "wAVfS4u00j-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[name] = accuracy\n",
        "    print(f\"{name}: Accuracy = {accuracy}\")\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYgnHYmx1nPg",
        "outputId": "02d7b138-a26c-498b-f170-2a6cea7f6951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: Accuracy = 0.6190476190476191\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.46      0.60        13\n",
            "           1       0.50      0.88      0.64         8\n",
            "\n",
            "    accuracy                           0.62        21\n",
            "   macro avg       0.68      0.67      0.62        21\n",
            "weighted avg       0.72      0.62      0.61        21\n",
            "\n",
            "Random Forest: Accuracy = 0.7619047619047619\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.69      0.78        13\n",
            "           1       0.64      0.88      0.74         8\n",
            "\n",
            "    accuracy                           0.76        21\n",
            "   macro avg       0.77      0.78      0.76        21\n",
            "weighted avg       0.80      0.76      0.77        21\n",
            "\n",
            "Naive Bayes: Accuracy = 0.6190476190476191\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.85      0.73        13\n",
            "           1       0.50      0.25      0.33         8\n",
            "\n",
            "    accuracy                           0.62        21\n",
            "   macro avg       0.57      0.55      0.53        21\n",
            "weighted avg       0.59      0.62      0.58        21\n",
            "\n",
            "Neural Network: Accuracy = 0.8571428571428571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.85      0.88        13\n",
            "           1       0.78      0.88      0.82         8\n",
            "\n",
            "    accuracy                           0.86        21\n",
            "   macro avg       0.85      0.86      0.85        21\n",
            "weighted avg       0.86      0.86      0.86        21\n",
            "\n",
            "Logistic Regression: Accuracy = 0.7142857142857143\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.69      0.75        13\n",
            "           1       0.60      0.75      0.67         8\n",
            "\n",
            "    accuracy                           0.71        21\n",
            "   macro avg       0.71      0.72      0.71        21\n",
            "weighted avg       0.74      0.71      0.72        21\n",
            "\n"
          ]
        }
      ]
    }
  ]
}